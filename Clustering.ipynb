{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8704: expected 15 fields, saw 22\\nSkipping line 16933: expected 15 fields, saw 22\\nSkipping line 23726: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 85637: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 132136: expected 15 fields, saw 22\\nSkipping line 158070: expected 15 fields, saw 22\\nSkipping line 166007: expected 15 fields, saw 22\\nSkipping line 171877: expected 15 fields, saw 22\\nSkipping line 177756: expected 15 fields, saw 22\\nSkipping line 181773: expected 15 fields, saw 22\\nSkipping line 191085: expected 15 fields, saw 22\\nSkipping line 196273: expected 15 fields, saw 22\\nSkipping line 196331: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 197000: expected 15 fields, saw 22\\nSkipping line 197011: expected 15 fields, saw 22\\nSkipping line 197432: expected 15 fields, saw 22\\nSkipping line 208016: expected 15 fields, saw 22\\nSkipping line 214110: expected 15 fields, saw 22\\nSkipping line 244328: expected 15 fields, saw 22\\nSkipping line 248519: expected 15 fields, saw 22\\nSkipping line 254936: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 272057: expected 15 fields, saw 22\\nSkipping line 293214: expected 15 fields, saw 22\\nSkipping line 310507: expected 15 fields, saw 22\\nSkipping line 312306: expected 15 fields, saw 22\\nSkipping line 316296: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 336028: expected 15 fields, saw 22\\nSkipping line 344885: expected 15 fields, saw 22\\nSkipping line 352551: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 408773: expected 15 fields, saw 22\\nSkipping line 434535: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 581593: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 652409: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"watch_reviews.tsv\", sep = '\\t', header = 0, error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 960204 entries, 0 to 960203\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   marketplace        960204 non-null  object\n",
      " 1   customer_id        960204 non-null  int64 \n",
      " 2   review_id          960204 non-null  object\n",
      " 3   product_id         960204 non-null  object\n",
      " 4   product_parent     960204 non-null  int64 \n",
      " 5   product_title      960202 non-null  object\n",
      " 6   product_category   960204 non-null  object\n",
      " 7   star_rating        960204 non-null  int64 \n",
      " 8   helpful_votes      960204 non-null  int64 \n",
      " 9   total_votes        960204 non-null  int64 \n",
      " 10  vine               960204 non-null  object\n",
      " 11  verified_purchase  960204 non-null  object\n",
      " 12  review_headline    960197 non-null  object\n",
      " 13  review_body        960056 non-null  object\n",
      " 14  review_date        960200 non-null  object\n",
      "dtypes: int64(5), object(10)\n",
      "memory usage: 109.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['review_body'], inplace = True) # inplace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the first 10000 data as out training data\n",
    "data = df.loc[:10007, 'review_body'].tolist()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append(\"'m\")\n",
    "stopwords.append(\"'s\")\n",
    "stopwords.append(\"br\")\n",
    "stopwords.append(\"n't\")\n",
    "stopwords.append(\"ve\")\n",
    "print(stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing_and_stemming(text):\n",
    "    tokens = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.lower() not in stopwords:\n",
    "            tokens.append(word.lower())\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if re.search('[a-z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['watch', 'face', 'great', 'leather', 'band', 'tear', 'alreadi', 'wear', 'day']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizing_and_stemming(data[9999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruoxi\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becom', 'besid', 'cri', 'describ', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'otherwis', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review number: 10000 terms number: 258\n"
     ]
    }
   ],
   "source": [
    "tfidf_model = TfidfVectorizer(max_df = 0.99, max_features = 1500, \n",
    "                             min_df= 0.01, stop_words='english',\n",
    "                             use_idf = True, tokenizer= tokenizing_and_stemming, ngram_range=(1,2))\n",
    "tfidf_matrix = tfidf_model.fit_transform(data)\n",
    "print(\"review number:\", tfidf_matrix.shape[0], 'terms number:',tfidf_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_model.get_params()\n",
    "tf_selected_words = tfidf_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x258 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 78851 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 5\n",
    "\n",
    "km = KMeans(n_clusters = num_clusters)\n",
    "km.fit(tfidf_matrix) \n",
    "\n",
    "# array to list\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Absolutely love this watch! Get compliments al...\n",
       "1         I love this watch it keeps time wonderfully.\n",
       "2                                            Scratches\n",
       "3    It works well on me. However, I found cheaper ...\n",
       "4    Beautiful watch face.  The band looks nice all...\n",
       "5    i love this watch for my purpose, about the pe...\n",
       "6    for my wife and she loved it, looks great and ...\n",
       "7    I was about to buy this thinking it was a Swis...\n",
       "8    Watch is perfect. Rugged with the metal &#34;B...\n",
       "9    Great quality and build.<br />The motors are r...\n",
       "Name: review_body, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10].review_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewcode = {\n",
    "    \"review\" : df[:10000].review_body,\n",
    "    \"cluster\": clusters\n",
    "}\n",
    "codedf = pd.DataFrame(reviewcode, columns = [\"review\",\"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely love this watch! Get compliments al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love this watch it keeps time wonderfully.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scratches</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It works well on me. However, I found cheaper ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beautiful watch face.  The band looks nice all...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i love this watch for my purpose, about the pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>for my wife and she loved it, looks great and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was about to buy this thinking it was a Swis...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Watch is perfect. Rugged with the metal &amp;#34;B...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Great quality and build.&lt;br /&gt;The motors are r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  cluster\n",
       "0  Absolutely love this watch! Get compliments al...        0\n",
       "1       I love this watch it keeps time wonderfully.        0\n",
       "2                                          Scratches        4\n",
       "3  It works well on me. However, I found cheaper ...        4\n",
       "4  Beautiful watch face.  The band looks nice all...        4\n",
       "5  i love this watch for my purpose, about the pe...        0\n",
       "6  for my wife and she loved it, looks great and ...        2\n",
       "7  I was about to buy this thinking it was a Swis...        4\n",
       "8  Watch is perfect. Rugged with the metal &#34;B...        2\n",
       "9  Great quality and build.<br />The motors are r...        2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codedf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster\n",
       "4     6598\n",
       "2     1169\n",
       "0      968\n",
       "3      639\n",
       "1      626"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codedf['cluster'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00136575, 0.02621321, 0.00050246, ..., 0.00285365, 0.00698811,\n",
       "        0.0087124 ],\n",
       "       [0.00084447, 0.        , 0.00159272, ..., 0.0036197 , 0.00346334,\n",
       "        0.00148756],\n",
       "       [0.00185264, 0.00231729, 0.00471825, ..., 0.00479869, 0.00926884,\n",
       "        0.01232898],\n",
       "       [0.        , 0.        , 0.00155345, ..., 0.00371263, 0.01063194,\n",
       "        0.0015916 ],\n",
       "       [0.00526333, 0.00436649, 0.00622658, ..., 0.00866152, 0.02330434,\n",
       "        0.01529667]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[136, 137, 232, ..., 167, 166, 127],\n",
       "       [ 94, 172,  97, ..., 196, 195, 127],\n",
       "       [ 99, 102, 232, ..., 195, 166,  32],\n",
       "       [148, 150, 232, ..., 167,  33,   0],\n",
       "       [232, 129, 123, ..., 253, 100, 101]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the feature by decresing importance\n",
    "order_centroids[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster  0 words:ll ,pin ,plastic ,origin ,great look ,hour ,button ,good watch ,second hand ,movement ,\n",
      "cluster  1 words:ll ,second hand ,seiko ,bought watch ,watch love ,bracelet ,sinc ,watch great ,watch face ,small wrist ,\n",
      "cluster  2 words:broke ,pin ,second hand ,like watch ,bracelet ,review ,easili ,quit ,ok ,model ,\n",
      "cluster  3 words:abl ,button ,plastic ,origin ,cute ,new ,metal ,digit ,bought watch ,hour ,\n",
      "cluster  4 words:great price ,great look ,work great ,watch great ,great watch ,good qualiti ,good watch ,watch good ,water resist ,look great ,\n"
     ]
    }
   ],
   "source": [
    "cluster_keyword={}\n",
    "for i in range(num_clusters):\n",
    "    print(\"cluster \", i, \"words:\", end = '')\n",
    "    cluster_keyword[i] = []\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        cluster_keyword[i].append(tf_selected_words[ind])\n",
    "        print(tf_selected_words[ind],\",\", end= '')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruoxi\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becom', 'besid', 'cri', 'describ', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'otherwis', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews: 10000 feature 258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tfidf_lda = CountVectorizer(max_df=0.99, max_features=1000,\n",
    "                           min_df=0.01, stop_words = 'english',\n",
    "                           tokenizer=tokenizing_and_stemming, ngram_range=(1,2))\n",
    "\n",
    "tfidf_matrix_lda = tfidf_lda.fit_transform(data)\n",
    "print(\"reviews:\",tfidf_matrix_lda.shape[0], \"feature\", tfidf_matrix_lda.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02258025 0.02241308 0.67944206 0.02285546 0.25270915]\n",
      " [0.04060411 0.04068079 0.59234168 0.04128062 0.28509279]\n",
      " [0.10000049 0.1009091  0.10000036 0.10086956 0.59822048]\n",
      " ...\n",
      " [0.00889445 0.15054642 0.22948582 0.60204023 0.00903309]\n",
      " [0.01011648 0.01018586 0.08810265 0.01017458 0.88142042]\n",
      " [0.020284   0.02009447 0.15395578 0.29438745 0.5112783 ]]\n"
     ]
    }
   ],
   "source": [
    "lda_output = lda.fit_transform(tfidf_matrix_lda)\n",
    "print(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.02088384e-01 2.03887426e-01 2.00357546e+01 ... 4.46877932e+01\n",
      "  5.33766960e+01 3.26986306e-01]\n",
      " [2.02123680e-01 2.11131816e-01 2.67615040e+01 ... 4.43596798e+01\n",
      "  1.48671398e+01 2.69605469e-01]\n",
      " [2.03392814e-01 1.26611337e+02 2.02404703e-01 ... 2.01223972e+01\n",
      "  1.92697030e+02 2.34791470e+01]\n",
      " [6.27145104e+01 2.07710581e-01 1.11143376e+01 ... 8.89311562e+01\n",
      "  4.02952140e+01 4.30784285e+02]\n",
      " [1.01677885e+02 2.37659331e+01 1.27885999e+02 ... 2.78989735e+01\n",
      "  5.98763920e+02 1.12139976e+02]]\n"
     ]
    }
   ],
   "source": [
    "topic_word = lda.components_\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic0  topic1  topic2  topic3  topic4  topic\n",
       "Doc0    0.02    0.02    0.68    0.02    0.25      2\n",
       "Doc1    0.04    0.04    0.59    0.04    0.29      2\n",
       "Doc2    0.10    0.10    0.10    0.10    0.60      4\n",
       "Doc3    0.43    0.03    0.03    0.47    0.03      3\n",
       "Doc4    0.15    0.15    0.14    0.14    0.41      4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_name = [\"topic\" + str(i) for i in range(lda.n_components)]\n",
    "doc_names = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "df_doc_topic = pd.DataFrame(np.round(lda_output, 2), columns= topic_name, index= doc_names)\n",
    "topic = np.argmax(df_doc_topic.values, axis = 1) # get the max value of the topic \n",
    "df_doc_topic['topic'] = topic\n",
    "df_doc_topic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic\n",
       "4   2676\n",
       "2   2231\n",
       "3   1921\n",
       "0   1714\n",
       "1   1458"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc_topic['topic'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accur</th>\n",
       "      <th>actual</th>\n",
       "      <th>adjust</th>\n",
       "      <th>alarm</th>\n",
       "      <th>alreadi</th>\n",
       "      <th>alway</th>\n",
       "      <th>amaz</th>\n",
       "      <th>amazon</th>\n",
       "      <th>...</th>\n",
       "      <th>weight</th>\n",
       "      <th>white</th>\n",
       "      <th>wife</th>\n",
       "      <th>wish</th>\n",
       "      <th>work</th>\n",
       "      <th>work great</th>\n",
       "      <th>worn</th>\n",
       "      <th>worth</th>\n",
       "      <th>wrist</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic0</th>\n",
       "      <td>0.202088</td>\n",
       "      <td>0.203887</td>\n",
       "      <td>20.035755</td>\n",
       "      <td>19.759086</td>\n",
       "      <td>0.203891</td>\n",
       "      <td>0.200855</td>\n",
       "      <td>0.429116</td>\n",
       "      <td>0.203780</td>\n",
       "      <td>0.226788</td>\n",
       "      <td>43.032776</td>\n",
       "      <td>...</td>\n",
       "      <td>24.733577</td>\n",
       "      <td>31.954617</td>\n",
       "      <td>129.681643</td>\n",
       "      <td>27.964251</td>\n",
       "      <td>0.413478</td>\n",
       "      <td>0.201453</td>\n",
       "      <td>4.625367</td>\n",
       "      <td>44.687793</td>\n",
       "      <td>53.376696</td>\n",
       "      <td>0.326986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic1</th>\n",
       "      <td>0.202124</td>\n",
       "      <td>0.211132</td>\n",
       "      <td>26.761504</td>\n",
       "      <td>1.231702</td>\n",
       "      <td>10.803901</td>\n",
       "      <td>24.210906</td>\n",
       "      <td>0.261693</td>\n",
       "      <td>14.631208</td>\n",
       "      <td>0.203015</td>\n",
       "      <td>0.202593</td>\n",
       "      <td>...</td>\n",
       "      <td>15.053441</td>\n",
       "      <td>0.201929</td>\n",
       "      <td>5.509059</td>\n",
       "      <td>0.203214</td>\n",
       "      <td>89.330168</td>\n",
       "      <td>1.041585</td>\n",
       "      <td>0.202665</td>\n",
       "      <td>44.359680</td>\n",
       "      <td>14.867140</td>\n",
       "      <td>0.269605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic2</th>\n",
       "      <td>0.203393</td>\n",
       "      <td>126.611337</td>\n",
       "      <td>0.202405</td>\n",
       "      <td>8.874735</td>\n",
       "      <td>15.455996</td>\n",
       "      <td>0.202435</td>\n",
       "      <td>2.768709</td>\n",
       "      <td>18.327735</td>\n",
       "      <td>141.342631</td>\n",
       "      <td>0.434699</td>\n",
       "      <td>...</td>\n",
       "      <td>23.306913</td>\n",
       "      <td>0.205083</td>\n",
       "      <td>3.255911</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>115.584576</td>\n",
       "      <td>124.860800</td>\n",
       "      <td>0.204043</td>\n",
       "      <td>20.122397</td>\n",
       "      <td>192.697030</td>\n",
       "      <td>23.479147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic3</th>\n",
       "      <td>62.714510</td>\n",
       "      <td>0.207711</td>\n",
       "      <td>11.114338</td>\n",
       "      <td>28.881846</td>\n",
       "      <td>1.392283</td>\n",
       "      <td>0.203656</td>\n",
       "      <td>104.716629</td>\n",
       "      <td>48.923030</td>\n",
       "      <td>22.949872</td>\n",
       "      <td>230.545662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201698</td>\n",
       "      <td>0.203933</td>\n",
       "      <td>0.203517</td>\n",
       "      <td>20.579897</td>\n",
       "      <td>854.999679</td>\n",
       "      <td>13.254165</td>\n",
       "      <td>47.850486</td>\n",
       "      <td>88.931156</td>\n",
       "      <td>40.295214</td>\n",
       "      <td>430.784285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic4</th>\n",
       "      <td>101.677885</td>\n",
       "      <td>23.765933</td>\n",
       "      <td>127.885999</td>\n",
       "      <td>140.252632</td>\n",
       "      <td>238.143929</td>\n",
       "      <td>136.182148</td>\n",
       "      <td>8.823853</td>\n",
       "      <td>88.914247</td>\n",
       "      <td>19.277694</td>\n",
       "      <td>24.784270</td>\n",
       "      <td>...</td>\n",
       "      <td>91.704371</td>\n",
       "      <td>102.434437</td>\n",
       "      <td>12.349871</td>\n",
       "      <td>109.291101</td>\n",
       "      <td>291.672098</td>\n",
       "      <td>0.641996</td>\n",
       "      <td>93.117439</td>\n",
       "      <td>27.898974</td>\n",
       "      <td>598.763920</td>\n",
       "      <td>112.139976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               abl     absolut       accur      actual      adjust  \\\n",
       "topic0    0.202088    0.203887   20.035755   19.759086    0.203891   \n",
       "topic1    0.202124    0.211132   26.761504    1.231702   10.803901   \n",
       "topic2    0.203393  126.611337    0.202405    8.874735   15.455996   \n",
       "topic3   62.714510    0.207711   11.114338   28.881846    1.392283   \n",
       "topic4  101.677885   23.765933  127.885999  140.252632  238.143929   \n",
       "\n",
       "             alarm     alreadi      alway        amaz      amazon  ...  \\\n",
       "topic0    0.200855    0.429116   0.203780    0.226788   43.032776  ...   \n",
       "topic1   24.210906    0.261693  14.631208    0.203015    0.202593  ...   \n",
       "topic2    0.202435    2.768709  18.327735  141.342631    0.434699  ...   \n",
       "topic3    0.203656  104.716629  48.923030   22.949872  230.545662  ...   \n",
       "topic4  136.182148    8.823853  88.914247   19.277694   24.784270  ...   \n",
       "\n",
       "           weight       white        wife        wish        work  work great  \\\n",
       "topic0  24.733577   31.954617  129.681643   27.964251    0.413478    0.201453   \n",
       "topic1  15.053441    0.201929    5.509059    0.203214   89.330168    1.041585   \n",
       "topic2  23.306913    0.205083    3.255911    0.961538  115.584576  124.860800   \n",
       "topic3   0.201698    0.203933    0.203517   20.579897  854.999679   13.254165   \n",
       "topic4  91.704371  102.434437   12.349871  109.291101  291.672098    0.641996   \n",
       "\n",
       "             worn      worth       wrist        year  \n",
       "topic0   4.625367  44.687793   53.376696    0.326986  \n",
       "topic1   0.202665  44.359680   14.867140    0.269605  \n",
       "topic2   0.204043  20.122397  192.697030   23.479147  \n",
       "topic3  47.850486  88.931156   40.295214  430.784285  \n",
       "topic4  93.117439  27.898974  598.763920  112.139976  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_words = pd.DataFrame(lda.components_)\n",
    "\n",
    "df_topic_words.columns = tfidf_lda.get_feature_names()\n",
    "df_topic_words.index = topic_name\n",
    "df_topic_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>watch</td>\n",
       "      <td>nice</td>\n",
       "      <td>beauti</td>\n",
       "      <td>price</td>\n",
       "      <td>nice watch</td>\n",
       "      <td>great</td>\n",
       "      <td>awesom</td>\n",
       "      <td>color</td>\n",
       "      <td>thank</td>\n",
       "      <td>beauti watch</td>\n",
       "      <td>cool</td>\n",
       "      <td>realli</td>\n",
       "      <td>purchas</td>\n",
       "      <td>best</td>\n",
       "      <td>watch price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>good</td>\n",
       "      <td>look</td>\n",
       "      <td>qualiti</td>\n",
       "      <td>watch</td>\n",
       "      <td>excel</td>\n",
       "      <td>product</td>\n",
       "      <td>price</td>\n",
       "      <td>nice</td>\n",
       "      <td>cheap</td>\n",
       "      <td>look good</td>\n",
       "      <td>perfect</td>\n",
       "      <td>look watch</td>\n",
       "      <td>nice look</td>\n",
       "      <td>time</td>\n",
       "      <td>easi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>love</td>\n",
       "      <td>watch</td>\n",
       "      <td>great</td>\n",
       "      <td>look</td>\n",
       "      <td>love watch</td>\n",
       "      <td>great watch</td>\n",
       "      <td>look great</td>\n",
       "      <td>gift</td>\n",
       "      <td>expect</td>\n",
       "      <td>husband</td>\n",
       "      <td>perfect</td>\n",
       "      <td>band</td>\n",
       "      <td>wrist</td>\n",
       "      <td>big</td>\n",
       "      <td>watch look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>watch</td>\n",
       "      <td>work</td>\n",
       "      <td>band</td>\n",
       "      <td>time</td>\n",
       "      <td>batteri</td>\n",
       "      <td>replac</td>\n",
       "      <td>year</td>\n",
       "      <td>recommend</td>\n",
       "      <td>strap</td>\n",
       "      <td>day</td>\n",
       "      <td>month</td>\n",
       "      <td>use</td>\n",
       "      <td>bought</td>\n",
       "      <td>buy</td>\n",
       "      <td>receiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>watch</td>\n",
       "      <td>like</td>\n",
       "      <td>time</td>\n",
       "      <td>look</td>\n",
       "      <td>band</td>\n",
       "      <td>face</td>\n",
       "      <td>use</td>\n",
       "      <td>wear</td>\n",
       "      <td>wrist</td>\n",
       "      <td>hand</td>\n",
       "      <td>read</td>\n",
       "      <td>easi</td>\n",
       "      <td>light</td>\n",
       "      <td>day</td>\n",
       "      <td>realli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word 0 Word 1   Word 2 Word 3      Word 4       Word 5      Word 6  \\\n",
       "Topic 0  watch   nice   beauti  price  nice watch        great      awesom   \n",
       "Topic 1   good   look  qualiti  watch       excel      product       price   \n",
       "Topic 2   love  watch    great   look  love watch  great watch  look great   \n",
       "Topic 3  watch   work     band   time     batteri       replac        year   \n",
       "Topic 4  watch   like     time   look        band         face         use   \n",
       "\n",
       "            Word 7  Word 8        Word 9  Word 10     Word 11    Word 12  \\\n",
       "Topic 0      color   thank  beauti watch     cool      realli    purchas   \n",
       "Topic 1       nice   cheap     look good  perfect  look watch  nice look   \n",
       "Topic 2       gift  expect       husband  perfect        band      wrist   \n",
       "Topic 3  recommend   strap           day    month         use     bought   \n",
       "Topic 4       wear   wrist          hand     read        easi      light   \n",
       "\n",
       "        Word 13      Word 14  \n",
       "Topic 0    best  watch price  \n",
       "Topic 1    time         easi  \n",
       "Topic 2     big   watch look  \n",
       "Topic 3     buy       receiv  \n",
       "Topic 4     day       realli  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_topic_words(tfidf_model, lda_model, n_words):\n",
    "    words = np.array(tfidf_model.get_feature_names())\n",
    "    topic_words = []\n",
    "    for topic_words_weights in lda_model.components_:\n",
    "        top_words = topic_words_weights.argsort()[::-1][:n_words]\n",
    "        topic_words.append(words.take(top_words))\n",
    "    return topic_words\n",
    "\n",
    "topic_keywords = print_topic_words(tfidf_model = tfidf_lda, lda_model= lda, n_words=15)\n",
    "\n",
    "df_topic_words = pd.DataFrame(topic_keywords)\n",
    "df_topic_words.columns = ['Word '+str(i) for i in range(df_topic_words.shape[1])]\n",
    "df_topic_words.index = ['Topic '+str(i) for i in range(df_topic_words.shape[0])]\n",
    "df_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
